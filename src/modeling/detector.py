import torch
import numpy as np
from torch import nn
from torch import optim
import lightning.pytorch as pl
from sklearn.metrics import accuracy_score, f1_score

whitelist_weight_modules = (torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d, nn.LSTM)
blacklist_weight_modules = (torch.nn.LayerNorm, torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, nn.Embedding)

def get_weight_decay_params(model):
    """ 
    Adapted from the implementation at
    https://github.com/karpathy/minGPT/blob/3ed14b2cec0dfdad3f4b2831f2b4a86d11aef150/mingpt/model.py#L136
    """
    decay = set()
    no_decay = set()
    for module_name, module in model.named_modules():
        for param_name, _ in module.named_parameters():
            fpn = '%s.%s' % (module_name, param_name) if module_name else param_name # full param name

            if 'bias' in param_name:
                # all biases will not be decayed
                no_decay.add(fpn)
            elif 'weight' in param_name and isinstance(module, whitelist_weight_modules):
                # weights of whitelist modules will be weight decayed
                decay.add(fpn)
            elif 'weight' in param_name and isinstance(module, blacklist_weight_modules):
                # weights of blacklist modules will NOT be weight decayed
                no_decay.add(fpn)
            elif 'attn' in param_name:
                decay.add(fpn)

    # validate that we considered every parameter
    param_dict = {pn: p for pn, p in model.named_parameters()}
    inter_params = decay & no_decay
    union_params = decay | no_decay
    assert len(inter_params) == 0, "parameters %s made it into both decay/no_decay sets!" % (str(inter_params), )
    assert len(param_dict.keys() - union_params) == 0, "parameters %s were not separated into either decay/no_decay set!" \
                                                % (str(param_dict.keys() - union_params), )
    
    decay =  [param_dict[pn] for pn in sorted(list(decay))]
    no_decay =  [param_dict[pn] for pn in sorted(list(no_decay))]

    return decay, no_decay

class VulnerabilityDetectionModel(pl.LightningModule):
    def __init__(self, model, from_scratch=False, num_classes=5, lr=1e-5, weight_decay=0.0, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        pl.seed_everything(42, workers=True)

        self.model = model
        self.loss_fct = nn.BCEWithLogitsLoss()
        if not from_scratch:
            layer_groups = self.model.get_layer_groups()
            for param in layer_groups['feature_extractor']:
                param.requires_grad = False
        
        self.lr = lr
        self.weight_decay = weight_decay
        self.num_classes = num_classes
        
    def configure_optimizers(self):
        decay, no_decay = get_weight_decay_params(self.model)
        param_groups = [
        {'params': decay, 'weight_decay': self.weight_decay},
        {'params': no_decay, 'weight_decay': 0.0}
    ]
        optimizer = optim.Adam(param_groups, lr=self.lr)
        return optimizer
    
    def training_step(self, batch, batch_idx):
        imgs = batch['image']
        labels = batch['label']
        if 'inception' in self.model.__class__.__name__.lower():
            out, aux_out = self.model(imgs)
            loss1 = self.loss_fct(out, labels)
            loss2 = self.loss_fct(aux_out, labels)
            loss = loss1 + 0.4 * loss2
        else:
            out = self.model(imgs)
            loss = self.loss_fct(out, labels)
        
        self.log('train_loss', loss.item(), on_epoch=True)
        return {'loss': loss, 'preds': out, 'labels': labels}

    def validation_step(self, batch,  batch_idx):
        out = self._shared_eval(batch, batch_idx, prefix="val")
        return out
    
    def test_step(self, batch, batch_idx):
        out = self._shared_eval(batch, batch_idx, prefix="test")
        return out
    
    def _compute_metrics(self, pred, labels):
        logged_metrics = {
            'micro_f1': f1_score(y_true=labels.detach().cpu(), y_pred=(pred > 0.0).detach().cpu(), labels=np.arange(0, self.num_classes), average='micro'),
            'macro_f1': f1_score(y_true=labels.detach().cpu(), y_pred=(pred > 0.0).detach().cpu(), labels=np.arange(0, self.num_classes), average='macro'),
            'acc': accuracy_score(y_true=labels.detach().cpu(), y_pred=(pred > 0.0).detach().cpu())
        }
        return logged_metrics
    
    def _shared_eval(self, batch, batch_idx, prefix):
        imgs, label = batch['image'], batch['label']
        out = self.model(imgs)
        loss = self.loss_fct(out, label)
        self.log(f'{prefix}_loss', loss.item())
        return {'preds': out, 'labels': label}
    
    def _shared_concat_and_eval(self, outputs):
        preds = torch.cat([x["preds"] for x in outputs])
        labels = torch.cat([x["labels"] for x in outputs])
        logged_metrics = self._compute_metrics(preds, labels)
        return logged_metrics
        
    def training_epoch_end(self, outputs):
        logged_metrics = self._shared_concat_and_eval(outputs)
        self.log_dict(logged_metrics)
    
    def validation_epoch_end(self, outputs):
        logged_metrics = self._shared_concat_and_eval(outputs)
        self.log_dict({f'val_{name}': value for name, value in logged_metrics.items()})
    
    def test_epoch_end(self, outputs):
        logged_metrics = self._shared_concat_and_eval(outputs)
        self.log_dict({f'test_{name}': value for name, value in logged_metrics.items()})